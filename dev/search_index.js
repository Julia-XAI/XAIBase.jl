var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Computing-explanations","page":"API Reference","title":"Computing explanations","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Most methods in the Julia-XAI ecosystem work by calling analyze on an input and an analyzer:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"analyze","category":"page"},{"location":"api/#XAIBase.analyze","page":"API Reference","title":"XAIBase.analyze","text":"analyze(input, method)\nanalyze(input, method, neuron_selection)\n\nApply the analyzer method for the given input, returning an Explanation. If neuron_selection is specified, e.g. the index of a specific output neuron, the explanation will be calculated for that neuron. Otherwise, the output neuron with the highest activation is automatically chosen.\n\nSee also Explanation and heatmap.\n\nKeyword arguments\n\nadd_batch_dim: add batch dimension to the input without allocating. Default is false.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API Reference","title":"API Reference","text":"The return type of analyze is an Explanation:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Explanation","category":"page"},{"location":"api/#XAIBase.Explanation","page":"API Reference","title":"XAIBase.Explanation","text":"Explanation(val, output, output_selection, analyzer, heatmap, extras)\n\nReturn type of analyzers when calling analyze.\n\nFields\n\nval: numerical output of the analyzer, e.g. an attribution or gradient\noutput: model output for the given analyzer input\noutput_selection: index of the output used for the explanation\nanalyzer: symbol corresponding the used analyzer, e.g. :Gradient or :LRP\nheatmap: symbol indicating a preset heatmapping style,   e.g. :attribution, :sensitivity or :cam\nextras: optional named tuple that can be used by analyzers   to return additional information.\n\n\n\n\n\n","category":"type"},{"location":"api/#Visualizing-explanations","page":"API Reference","title":"Visualizing explanations","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Explanations can be visualized using heatmap:","category":"page"},{"location":"api/","page":"API Reference","title":"API Reference","text":"heatmap","category":"page"},{"location":"api/#XAIBase.heatmap","page":"API Reference","title":"XAIBase.heatmap","text":"heatmap(explanation)\n\nVisualize Explanation from XAIBase as a vision heatmap. Assumes WHCN convention (width, height, channels, batchsize) for explanation.val.\n\nKeyword arguments\n\ncolorscheme::Union{ColorScheme,Symbol}: color scheme from ColorSchemes.jl. Defaults to :seismic.\nreduce::Symbol: Selects how color channels are reduced to a single number to apply a color scheme. The following methods can be selected, which are then applied over the color channels for each \"pixel\" in the array:\n:sum: sum up color channels\n:norm: compute 2-norm over the color channels\n:maxabs: compute maximum(abs, x) over the color channels\nDefaults to :sum.\nrangescale::Symbol: Selects how the color channel reduced heatmap is normalized before the color scheme is applied. Can be either :extrema or :centered. Defaults to :centered.\nprocess_batch::Bool: When heatmapping a batch, setting process_batch=true will apply the rangescale normalization to the entire batch instead of computing it individually for each sample in the batch. Defaults to false.\npermute::Bool: Whether to flip W&H input channels. Default is true.\nunpack_singleton::Bool: If false, heatmap will always return a vector of images. When heatmapping a batch with a single sample, setting unpack_singleton=true will unpack the singleton vector and directly return the image. Defaults to true.\n\n\n\n\n\nheatmap(input, analyzer)\n\nCompute an Explanation for a given input using the method analyzer and visualize it as a vision heatmap.\n\nAny additional arguments and keyword arguments are passed to the analyzer. Refer to analyze for more information on available keyword arguments.\n\nTo customize the heatmapping style, first compute an explanation using analyze and then call heatmap on the explanation.\n\n\n\n\n\nheatmap(explanation, text)\n\nVisualize Explanation from XAIBase as text heatmap. Text should be a vector containing vectors of strings, one for each input in the batched explanation.\n\nKeyword arguments\n\ncolorscheme::Union{ColorScheme,Symbol}: color scheme from ColorSchemes.jl. Defaults to :seismic.\nrangescale::Symbol: selects how the color channel reduced heatmap is normalized before the color scheme is applied. Can be either :extrema or :centered. Defaults to :centered for use with the default color scheme :seismic.\n\n\n\n\n\n","category":"function"},{"location":"api/#Feature-selection","page":"API Reference","title":"Feature selection","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"IndexedFeatures\nTopNFeatures","category":"page"},{"location":"api/#XAIBase.IndexedFeatures","page":"API Reference","title":"XAIBase.IndexedFeatures","text":"IndexedFeatures(indices...)\n\nSelect features by indices.\n\nFor outputs of convolutional layers, the index refers to a feature dimension.\n\nSee also See also TopNFeatures.\n\n\n\n\n\n","category":"type"},{"location":"api/#XAIBase.TopNFeatures","page":"API Reference","title":"XAIBase.TopNFeatures","text":"TopNFeatures(n)\n\nSelect top-n features.\n\nFor outputs of convolutional layers, the relevance is summed across height and width channels for each feature.\n\nSee also IndexedFeatures.\n\n\n\n\n\n","category":"type"},{"location":"api/#Internals","page":"API Reference","title":"Internals","text":"","category":"section"},{"location":"api/#Output-selection","page":"API Reference","title":"Output selection","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"XAIBase.MaxActivationSelector\nXAIBase.IndexSelector","category":"page"},{"location":"api/#XAIBase.MaxActivationSelector","page":"API Reference","title":"XAIBase.MaxActivationSelector","text":"MaxActivationSelector()\n\nNeuron selector that picks the output neuron with the highest activation.\n\n\n\n\n\n","category":"type"},{"location":"api/#XAIBase.IndexSelector","page":"API Reference","title":"XAIBase.IndexSelector","text":"IndexSelector(index)\n\nNeuron selector that picks the output neuron at the given index.\n\n\n\n\n\n","category":"type"},{"location":"api/#Index","page":"API Reference","title":"Index","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"examples/#examples","page":"Example Implementations","title":"Example Implementations","text":"","category":"section"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"The following examples demonstrate the implementation of XAI methods using the XAIBase.jl interface. To evaluate our methods, we load a small, pre-trained LeNet5 model and the MNIST dataset:","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"using Flux\nusing BSON\n\nmodel = BSON.load(\"model.bson\", @__MODULE__)[:model] # load pre-trained LeNet-5 model","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"using MLDatasets\nusing ImageCore, ImageIO, ImageShow\n\nindex = 10\nx, y = MNIST(Float32, :test)[10]\n\n# By convention in Flux.jl, the input needs to be resized to WHCN format\n# by adding a color channel and batch dimensions.\ninput = reshape(x, 28, 28, 1, :);\n\nconvert2image(MNIST, x)","category":"page"},{"location":"examples/#Example-1:-Random-explanation","page":"Example Implementations","title":"Example 1: Random explanation","text":"","category":"section"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"To get started, we implement a nonsensical method that returns a random explanation in the shape of the input.","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"using XAIBase\n\nstruct RandomAnalyzer{M} <: AbstractXAIMethod \n    model::M    \nend\n\nfunction (method::RandomAnalyzer)(input, output_selector::AbstractNeuronSelector)\n    output = method.model(input)\n    output_selection = output_selector(output)\n\n    val = rand(size(input)...)\n    return Explanation(val, output, output_selection, :RandomAnalyzer, :sensitivity, nothing)\nend","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"We can directly use XAIBase's analyze and heatmap functions  to compute and visualize the random explanation:","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"analyzer = RandomAnalyzer(model)\nheatmap(input, analyzer)","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"As expected, the explanation is just noise.","category":"page"},{"location":"examples/#Example-2:-Input-sensitivity","page":"Example Implementations","title":"Example 2: Input sensitivity","text":"","category":"section"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"In this second example, we naively reimplement the Gradient analyzer from ExplainableAI.jl.","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"using XAIBase\nusing Zygote: gradient\n\nstruct MyGradient{M} <: AbstractXAIMethod \n    model::M    \nend\n\nfunction (method::MyGradient)(input, output_selector::AbstractNeuronSelector)\n    output = method.model(input)\n    output_selection = output_selector(output)\n\n    grad = gradient((x) -> only(method.model(x)[output_selection]), input)\n    val = only(grad)\n    return Explanation(val, output, output_selection, :MyGradient, :sensitivity, nothing)\nend","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"note: Note\nExplainableAI.jl implements the Gradient analyzer in a more efficient way  that works with batched inputs and only requires a single forward  and backward pass through the model.","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"Once again, we can directly use XAIBase's analyze and heatmap functions","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"analyzer = MyGradient(model)\nexpl = analyze(input, analyzer)\nheatmap(expl)","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"heatmap(expl, reduce=:norm, colorscheme=:twilight)","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"and make use of all the features provided by the Julia-XAI ecosystem.","category":"page"},{"location":"examples/","page":"Example Implementations","title":"Example Implementations","text":"note: Note\nFor an introduction to the Julia-XAI ecosystem,  please refer to the Getting started guide.","category":"page"},{"location":"#docs-interface","page":"XAIBase Interface","title":"Interface description","text":"","category":"section"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"XAIBase.jl is a light-weight dependency that defines the interface of XAI methods  in the Julia-XAI ecosystem.","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"Building on top of XAIBase  (or providing an interface via package extensions) makes your package compatible with the Julia-XAI ecosystem, allowing you to automatically compute heatmaps for vision and language models. ","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"This only requires you to fulfill the following two requirements:","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"An XAI method has to be a subtype of AbstractXAIMethod\nAn XAI method has to implement the following method: ","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"(method::MyMethod)(input, output_selector::AbstractNeuronSelector)","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"The method has to return an Explanation\nThe input is expected to have a batch dimensions as its last dimension\nWhen applied to a batch, the method returns a single Explanation,  which contains the batched output in the val field.\nAbstractNeuronSelectors are predefined callable structs  that select a single scalar value from a model's output,  e.g. the maximally activated output neuron of a classifier using XAIBase.MaxActivationSelector or a specific output neuron using XAIBase.IndexSelector.","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"Refer to the Explanation documentation for a description of the expected fields. For more information, take a look at src/XAIBase.jl.","category":"page"},{"location":"#Implementation-template","page":"XAIBase Interface","title":"Implementation template","text":"","category":"section"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"Julia-XAI methods will usually follow the following template:","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"struct MyMethod{M} <: AbstractXAIMethod \n    model::M    \nend\n\nfunction (method::MyMethod)(input, output_selector::AbstractNeuronSelector)\n    output = method.model(input)\n    output_selection = output_selector(output)\n\n    val = ...         # your method's implementation\n    extras = nothing  # optionally add additional information using a named tuple\n    return Explanation(val, output, output_selection, :MyMethod, :attribution, extras)\nend","category":"page"},{"location":"","page":"XAIBase Interface","title":"XAIBase Interface","text":"Refer to the example implementations for more information.","category":"page"}]
}
